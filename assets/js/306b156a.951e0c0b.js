"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[3862],{3905:(e,r,t)=>{t.d(r,{Zo:()=>c,kt:()=>d});var n=t(7294);function a(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function o(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);r&&(n=n.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,n)}return t}function i(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?o(Object(t),!0).forEach((function(r){a(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function l(e,r){if(null==e)return{};var t,n,a=function(e,r){if(null==e)return{};var t,n,a={},o=Object.keys(e);for(n=0;n<o.length;n++)t=o[n],r.indexOf(t)>=0||(a[t]=e[t]);return a}(e,r);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)t=o[n],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var s=n.createContext({}),p=function(e){var r=n.useContext(s),t=r;return e&&(t="function"==typeof e?e(r):i(i({},r),e)),t},c=function(e){var r=p(e.components);return n.createElement(s.Provider,{value:r},e.children)},m="mdxType",u={inlineCode:"code",wrapper:function(e){var r=e.children;return n.createElement(n.Fragment,{},r)}},g=n.forwardRef((function(e,r){var t=e.components,a=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),m=p(t),g=a,d=m["".concat(s,".").concat(g)]||m[g]||u[g]||o;return t?n.createElement(d,i(i({ref:r},c),{},{components:t})):n.createElement(d,i({ref:r},c))}));function d(e,r){var t=arguments,a=r&&r.mdxType;if("string"==typeof e||a){var o=t.length,i=new Array(o);i[0]=g;var l={};for(var s in r)hasOwnProperty.call(r,s)&&(l[s]=r[s]);l.originalType=e,l[m]="string"==typeof e?e:a,i[1]=l;for(var p=2;p<o;p++)i[p]=t[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,t)}g.displayName="MDXCreateElement"},6399:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>s,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var n=t(7462),a=(t(7294),t(3905));const o={},i="Chapter 1. The Benefits of Using GPUs",l={unversionedId:"\u5e76\u884c/CUDA/CUDA C++ Programming Guide",id:"\u5e76\u884c/CUDA/CUDA C++ Programming Guide",title:"Chapter 1. The Benefits of Using GPUs",description:"Compare to CPU:",source:"@site/docs/\u5e76\u884c/CUDA/CUDA C++ Programming Guide.md",sourceDirName:"\u5e76\u884c/CUDA",slug:"/\u5e76\u884c/CUDA/CUDA C++ Programming Guide",permalink:"/cpp/\u5e76\u884c/CUDA/CUDA C++ Programming Guide",draft:!1,tags:[],version:"current",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"GPU \u5185\u5b58\u7ed3\u6784",permalink:"/cpp/\u5e76\u884c/GPU \u5185\u5b58\u7ed3\u6784"},next:{title:"Introduction",permalink:"/cpp/\u5e76\u884c/\u7b97\u5b50\u52a0\u901f\u601d\u8def/GEMM \u7b97\u5b50\u8c03\u4f18"}},s={},p=[],c={toc:p};function m(e){let{components:r,...o}=e;return(0,a.kt)("wrapper",(0,n.Z)({},c,o,{components:r,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"chapter-1-the-benefits-of-using-gpus"},"Chapter 1. The Benefits of Using GPUs"),(0,a.kt)("p",null,"Compare to CPU:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Much higher instruction throughput and memory bandwidth"),(0,a.kt)("li",{parentName:"ul"},"A similar price and power envelope")),(0,a.kt)("p",null,"The GPU is designed to excel at executing thousands of them in parallel (\u5c3d\u7ba1\u5355\u7ebf\u7a0b\u6bd4\u4e0d\u4e0a CPU\uff0c\u4f46\u80dc\u5728\u6570\u91cf\u8db3\u591f\u5927)\u3002\n",(0,a.kt)("img",{src:t(3660).Z,width:"1168",height:"642"})),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"In general, an application has a mix of parallel parts and sequential parts, so systems are designed with a mix of GPUs and CPUs in order to maximize overall performance.")),(0,a.kt)("h1",{id:"chapter-2-cuda-a-general-purpose-parallel-computing-platform-and-programming-model"},"Chapter 2. CUDA: A General-Purpose Parallel Computing Platform and Programming Model"),(0,a.kt)("p",null,(0,a.kt)("img",{src:t(1871).Z,width:"1266",height:"1144"})),(0,a.kt)("h1",{id:"chapter-3-a-scalable-programming-model"},"Chapter 3. A Scalable Programming Model"),(0,a.kt)("p",null,"The advent of multicore CPUs and manycore GPUs means that mainstream processor chips are now parallel systems. The challenge is to develop application software that transparently scales its parallelism to leverage the increasing number of processor cores, much as 3D graphics applications trans- parently scale their parallelism to manycore GPUs with widely varying numbers of cores."),(0,a.kt)("p",null,"The CUDA parallel programming model is designed to overcome this challenge while maintaining a low learning curve for programmers familiar with standard programming languages such as C."),(0,a.kt)("h1",{id:"memory-hierarchy"},"Memory Hierarchy"),(0,a.kt)("p",null,(0,a.kt)("img",{src:t(4217).Z,width:"1912",height:"1326"})))}m.isMDXComponent=!0},3660:(e,r,t)=>{t.d(r,{Z:()=>n});const n=t.p+"assets/images/Pasted image 20230808155928-44f1e330e95ec54f39201311fa9ab170.png"},1871:(e,r,t)=>{t.d(r,{Z:()=>n});const n=t.p+"assets/images/Pasted image 20230808161005-81a46769065d5c7ffe5e0ac6907988f0.png"},4217:(e,r,t)=>{t.d(r,{Z:()=>n});const n=t.p+"assets/images/Pasted image 20230808171058-899cebb265d4138a0b68af05cda8329c.png"}}]);